---
title: "Végső porjekt"
author: "Jászai Tamás és Szutor Bálint"
date: '2020.01.16. '
output: html_document
---

# Cél: League of Legends (LoL) mérkőzések eredményének előrejelzése

Az eredeti motívációt az volt, hogy a LoL egy digitális játék/(e-)sport, így a mérkőzésekről könnyebb real-time adatokat szerezni, mint nem digitális játékokról/sportokról (pl. futball, kosárlabda, stb.). Ez business szempontból azért érdekes, mert így egy jó előrejelző modell 1) segíthet real-time fogadások megkötésében, és igazán jól működő modellek esetében elméleti szinten pozitív várható értékű fogadásokat is köthetünk, illetve 2) segíthet a real-time fogadások árazásának kialakításába a fogadóirodák számára.

Sajnos nem tudtuk végül megoldani, hogy az adataink ne a mérkőzések végső statisztikáit tükrözzék (azaz, nem voltak pl. a meccs felénél összegyűjtött adataink, így nem tudtuk azt letesztelni, hogy a meccsek felének adatai alapján milyen pontossággal lehet előrejelezni a végeredményt). Emiatt csak a végső statisztikákból próbáltuk előrejelezni a meccsek kimenetelét, ami nem ad igazi választ a kérdésfeltevésünkre. Emiatt érdemesnek tartjuk a kérdésre való visszatérést a későbbiekben, megfelelő adathalmaz beszerzését követően.

Módszertan:

Többféle modellt használtunk. Az első részben megpróbáltuk a megfelelő változók kiválasztásával felépíteni a modellt (GLM, LVQ, RFE), később pedig kipróbáltunk egy számunkra új, PCR alapú modellt is, melyet az alábbi cikkben találtunk: https://www.sciencedirect.com/science/article/pii/S0167947318300562, itt a változóknak egy kombinációja lett volna használva.

Az volt az előzetes elképzelésünk, hogy a PCR alapú modell jobban fog teljesíteni. Ennek oka, hogy nagy korreláció az egyes változók értéke között, ezért a muiltikollinearitás problémáját jobban kezelő PCR alapú modellt előzetesen jobbnak vártuk.

Ezekről részletesebben alább beszámolunk.

# A projekt megvalósításának egyes lépései:

Adat keresés
Felderítő adatelemzés
Adat tisztítás
Modellek illesztése, validációja

Ezekről egyesével részletesebb beszámoló alább található:

# Adat kereses

Mint korábban említettük, sajnos nem tudtuk a mérkőzések "köztes eredményeit" leíró adatokat találni.
A felhasznált adatok forrása a Riot Games API, innen kértük le az adatokat egy Python kóddal, amit alább beillesztettünk.
Azért a Riot Games API-ja elég korlátozott mennyiségű adat lekérését tette lehetővé, de más forrást sajnos nem találtunk. Emiatt csak néhány ezer mérkőzésről sikerült adatokat szereznünk.
Pozitívum viszont, hogy sok változó (80+) szerepelt az adatbázisban.

```{r}

# Nem tudtuk kiexportálni HTML-be, amíg nem raktuk at R kód blokka, elnézést a gépemen sajnos elég sok furcsa R Studio hiba szembejön.

# import cassiopeia as cass
# import pandas as pd
# import time
# 
# cass.set_riot_api_key("")
# players = [""]
# 
# ids = []
# champions = []
# masteries = []
# sides = []
# sides = []
# win = []
# stats = []
# summonername = []
# date = []
# 
# for name in players:
#     #Create data frame to populate with matches
#     playerdata = cass.get_summoner(name = name, region = "EUNE")
#     match = playerdata.match_history
# 
#     for matchnum in range(len(match)):
#         print(matchnum, len(match))
#         time.sleep(0.1)
#         for sumnum in range(10):
#             if "fives" in match[matchnum].queue.name and "coop" not in match[matchnum].queue.name:
#                 try:
#                     date.append(match[matchnum].creation)
#                     ids.append(match[matchnum].id)
#                     champions.append(match[matchnum].participants[sumnum].champion.name)
#                     summonername.append(match[matchnum].participants[sumnum].summoner.name)
#                     a = match[matchnum].participants[sumnum].summoner.champion_masteries.filter(lambda cm: cm.champion.name == champions[matchnum])
#                     if len(a) > 0:
#                             masteries.append(a[0].points)
#                     else:
#                             masteries.append("NA")
#                     sides.append(match[matchnum].participants[sumnum].side)
#                     win.append(match[matchnum].red_team.win)
#                     stats.append(match[matchnum].participants[sumnum].stats.to_dict().values())
#                 except:
#                     mylists = [date, ids, champions, masteries, sides, win, stats]
#                     for currlist in mylists:
#                         if len(currlist) < len(ids):
#                             currlist.append("NA")
# 
#     lists_together = list(zip(ids, summonername, champions, masteries, sides, win, stats))
#     df = pd.DataFrame(lists_together)
# 
#     df.to_csv("LeaugeData" + name + ".csv")
# 
#     ids = []
#     champions = []
#     masteries = []
#     sides = []
#     win = []
#     stats = []
#     summonername = []
#     date = []
```

# Packagek
```{r}
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(tidyverse))

set.seed(1997)
```


# Adat tisztitas

Az adatokban találtunk:
- sok ismétlődő információt,
- hiányos adatsorokat,
- nem numerikus változókat,
- ID-ket,
- valójában semmitmondó változókat: vagy már "kivették" a játékból és semmi szerepe nincsen, vagy gyakorlatilag sosem volt benne/volt szerepe.

Ezek kezelésére tisztítottuk az adathalmazt.

Továbbá az adathalmaz minden meccsre játékos szinten mutatja a statsiztikákat: egy meccset két 5 fős csapat játszik, és az adathalmazban egy-egy sor egy játékosnak felel meg (de meghatározható, hogy mely meccset melyik 10 játékos játszotta, és hogyan oszlottak meg a csapatok között: ugyanis egymást követő adatsorok alkotnak egy-egy meccset). Számunkra ugyanakkor hasznosabbak voltak a modellépítés szempontjából a csapatszintű adatok, ezért meccsenként a két csapatra aggregáltuk a csapatot alkotó játékosok egyéni adatait.

Az így kapott adattal az a probléma, hogy a LoL meccsek hossza nem jól definiált (meccsenként nagyon változó lehet), ugyanakkor erősen korrelál a megfigyelt változóinkkal (példa: meccs alatt okozott összes sebzés erősen korrelál a meccs hosszával). Emiatt egy változó valamilyen (pl. kis) értéke nem feltétlen jelentené azt, hogy a csapat rosszul teljesített, lehet, hogy csak a mérkőzés hosszát tükrözné. Mi ezt a problémát úgy kezeltük, hogy a meccsenként kiszámított, két csapatra külön-külön aggregált értékek különbségét vettük, és ezt használtuk a későbbi modellekben. Ennek az eljárásnak előnye, hogy amennyiben a csapatok tagjait azonos metódussal választja ki a játék (így teszi), akkor a különbségek várható értéke 0 lesz a meccs hosszától függetlenül. Természetesen a különbségek szórása erősen összefügg továbbra is a meccs hosszával, ezt a problémát nem sikerült jól kezelnünk.

Az alábbiakban rövidebb kommentekkel olvasható a kódunk:
```{r}
data <- fread("data/LeaugeDataMege_clean.csv", dec = ",")
full_data <- data

# Eldobtuk az olyan meccseket, ahol hiányzott valamilyen adat:
a <- data[, .N, IDs]
correct_ids <- a$IDs[a$N == 10]
data <- data[data[, IDs %in% correct_ids]]

# Csapatonként csoportosítás:
data_blue <- data[Sides == "Side.blue"]
data_red <- data[Sides == "Side.red"]

# Nem numerikus oszlopok elválsztása + használhatatlan adatok kidobálása:
non_numeric_columns <- c("SummonerName", "Champion", "Sides", "Redw", "item0", "item1", "item2", "item3", "item4", "item5", "item6", "playerScore1", "playerScore2", "playerScore3", "playerScore4", "playerScore5", "playerScore6", "playerScore7", "playerScore8", "playerScore9", "combatPlayerScore", "totalPlayerScore", "firstBloodAssist", "objectivePlayerScore", "totalScoreRank", "playerScore0", "sightWardsBoughtInGame", "unrealKills", "participantId", "perkSubStyle", "perkPrimaryStyle", "champLevel", "firstInhibitorAssist", "firstInhibitorKill", "firstBloodKill", "firstTowerAssist", "firstTowerKill", "quadraKills", "pentaKills")

data_blue[, c(non_numeric_columns):=NULL]
data_red[, c(non_numeric_columns):=NULL]

data_blue_sum <- aggregate(. ~IDs, data_blue, FUN = "sum") %>% data.table()
data_red_sum <- aggregate(. ~IDs, data_red, FUN = "sum") %>% data.table()

# Győzelem vektor
wins <- data[Sides == "Side.red", .(winner = sum(win)), by = list(IDs, Sides)]
used_ids <- data.table(cbind(wins$winner/5, data_red_sum$IDs))
names(used_ids) <- c("win", "IDs")

data_red_sum[,c("IDs", "win"):=NULL]
data_blue_sum[,c("IDs", "win"):=NULL]

# Csapatok közti különbségek kiszámítása:

diff <- data.table(as.matrix(data_red_sum) - as.matrix(data_blue_sum))

data <- cbind(used_ids, diff)
```

# Adat felfedezes

Ábrákon próbáltunk összefüggéeseket keresni. Fontos volt, hogy olyan változókat szerepeltessünk, amelyek nem részhalmaza egymásnak (ekkor nyilván van bizonyos összzefüggés). Néhányat ezekből szemléltet az alábbi kód:
```{r}
ggplot(full_data, aes(x = goldEarned, y = totalDamageDealt)) + 
  geom_point() +
  xlab("Sebzés") +
  ylab("Csapat álal keresett arany") +
  ggtitle("Sebzés és aranyköltés közötti összefüggés, az összes adaton")
ggplot(data, aes(x = goldEarned, y = totalDamageDealt)) + 
  geom_point() + 
  xlab("Sebzés") +
  ylab("Csapat álal keresett arany") +
  ggtitle("Sebzés és aranyköltés közötti összefüggés, a már differenciált adatunkon")
# Látszódik a két ábrán, hogy ahol a full adatot használtuk, azaz ott, ahol nem a különbségét vettük az adatoknak, ott az adatok sokkal inkább szoródtak és kisebb volt a kapcsolat. Ez szerintünk azért van, mert a játék hossza torzít.


# Fontos azt is látni, hogy néhány változónk szinte csak egymás ellentétje de egyenlő, erre egy példa lehet:
ggplot(data, aes(x = deaths, y = kills)) + 
  geom_point() + 
  xlab("Halálok száma") +
  ylab("Gyilkosságok száma") +
  ggtitle("Gyilkosságok és halálok száma egymás ellentétje")


# Vagy ami számomra érdekes volt, hogy például a true damage (ami egy olyan sebzés fajta a játékban, amit nem lehet levédeni), nagyon hasonló mindig a csapatok között és erősen a 0 körül szórodik
ggplot(data, aes(x = trueDamageDealt, y = trueDamageTaken)) + 
  geom_point() + 
  xlab("Igaz sebzés sebezve") +
  ylab("Igaz sebzés elszenvedve") +
  ggtitle("Igaz sebzés látványosan a 0 körül szórodik")


# Mennyi aranyat költöttek, és ezzel mennyi sebzést tudtak okozni
ggplot(data, aes(x = totalDamageDealt, y = goldSpent)) + 
  geom_point() +
  xlab("Sebzés")+
  ylab("Csapat álal költött arany") +
  ggtitle("Sebzés és aranyköltés közötti összefüggés")

# Érdekes lehet, hogy vajon a győztes csapat hatékonyabb-e az arany használatban:

ggplot(full_data, aes(x = totalDamageDealt, y = goldSpent)) + 
  geom_point() + 
  facet_grid(rows = full_data$win) +
  xlab("Sebzés")+
  ylab("Csapat álal költött arany") +
  ggtitle("Sebzés és aranyköltés közötti összefüggés, győzelem alapján lebontva")
# Nem látszik jelentősnek a különbség, de a győztes csapat többet szóródik, ezért mi úgy gondoljuk, hogy egy apró mértékben hatékonyabban fordították át az aranyukat sebzéssé.

# Érdekes lehet a win rate-je a piros csapatnak a mintánkban, ha nem 50% közeli, akkor lehet torzított a mintánk 
print("Piros csapat győzelmi rátája a mintánkban:")
sum(used_ids$win) / length(used_ids$win)
# Nagyjabol stimmel, nincsen óriási eltérés

corr_mat <- cor(data[,-c(2)])

big_correlations <- as.data.table(as.table(corr_mat))
big_correlations <- big_correlations[order(N)]

head(big_correlations, n = 20)
head(big_correlations[V1 == "win"], n = 20)
# Bár az új eredményünk egy jelentős része meglehetősen egyértelmű, számunkra a death-goldEarned változó ennyire erős korrelációja mégis meglepő. Rengeteg módja van az aranyszerzésnek a játékban és az, hogy a halálok ennyire együtt mozognak vele minket meglepett: talán azért lehet így és azért nem látjuk ugyanúgy a kills változót, mert miután az ember meghal, amíg újra fel nem éled nem tud aranyat szerezni, azonban az ellenfélnek aranyat adott a halálával, és mivel mi a csapatok közötti különbséget vizsgáljuk ezért ez erősebben hat.
```

# Challange modell
```{r}
# Már nem lesz szükségünk a meccsek ID-aira
data[, IDs:= NULL]

# Az adatok 85%-át használjuk trainingre
set.seed(2020)
samp <- sample(nrow(data), nrow(data)*0.85)

# Létrehozunk egy training és egy teszt adathalmazt amit később használni tudunk
train <- data[samp,]
test <- data[-samp,]

# Test adathalmazban érdekes lehet tudni mennyi a win-rate ezt a számot ugyanis elérhetjük úgyis, ha csak mindenre azt mondjuk, hogy nyer
print(sum(test$win)/length(test$win))

# Mivel az eredményünket fogadásra szeretnénk használni, ezért ami valóban fontos számunkra, hogy amire fogadunk az valóban nyerő legyen, ezért a leghasznosabb ha precision-t mérünk. Ez a mi esetünkban annyit tesz, hogy azok közül a meccsek közül amikre fogadunk, hány fog valóban nyerni.
precision <- function(table){
  return(table[2,2] / (table[2,2] + table[2,1]))
}

# Modellek

model <- glm(as.factor(win) ~ goldEarned + totalDamageDealtToChampions + totalTimeCrowdControlDealt, data = train, family = "binomial")

pred_prob <- predict(model, type = "response", newdata = test)
pred_response <- rep("Lose", length(pred_prob))
pred_response[pred_prob > .5] <- "Win"

result_table <- table(pred_response, test$win)
print(precision(result_table))
print(result_table)

# Ebbe a modellbe két olyan változót tettünk be, ami a véleményünk szerint a legjobban kellene magyarázza a győzelem esélyeit. Ennek ellenére úgy fest, hogy ez a modell mégsem igérkezik túl jónak, ahogy a precision számon látható.

# CARET MEGOLDÁSOK

# Mivel rengeteg váltónk van, ezért érdemes lehet arra is módszert találjunk, hogy hogyan fogunk közöttük választani. Erre én kettő megoldást találtam: 

# 1. Megoldás: LVQ
# Az LVQ hasonlóan a K-meanshez codebook vektorokat hoz létre és annak a segítségével prediktálunk később. Ami nekem nagy előnyének tűnt, hogy könnyen ábrázolni is tudjuk, hogy milyen fontos 1-1 változó és azzal tudunk aztán prediktálni. Így nekem nagyon érdekes volt, hogy miután több seed mellett is lefutattam a programot a totalCCingOthers változó szinte mindig benne volt a legfontosabb változók között (CC: Crowd control), ami azt jelenti, hogy a győzelemhez nagyon erősen hozzájárul, hogy mennyi ideig tudjuk az ellenfél csapatot mozgásképtelenné tenni.

# Online olvasás után a legtöbb helyen azt ajánlották, hogy ha ezeket a modelleket szeretnénk használni, akkor előtte mindenképpen érdemes eltávolitani a nagyon együttmozgó változókat, 
highlyCorrelated <- findCorrelation(corr_mat, cutoff = 0.75)

train <- train[, c(highlyCorrelated):= NULL]
test <- test[, c(highlyCorrelated):= NULL]

set.seed(2020)
control <- trainControl(method = "repeatedCV", number = 10, repeats = 3)
model <- train(as.factor(win) ~., data = train, method = "lvq", preProcess = "scale", trControl = control)
importance <- varImp(model, scale = FALSE)
plot(importance)

pred_prob <- predict(model, newdata = test)

result_table <- table(pred_prob, test$win)
print(precision(result_table))
print(result_table)
# Úgy fest, hogy a sebzéseket tartja a legfontosabbnak ez a modell, ami persze érthető, azonban elképzelhető rengeteg olyan eset ahol a kevesebbet sebző csapat képes végül győzni. A precision szám nem győzött meg minket arról, hogy ezt a modellt lenne érdemes használni.


# RFE model selection
# Ahogy azt már említettük korábban, az adatainkban rengeteg olyan oszlop is van, ami valószínűleg nem sokkal járul hozzá egy csapat győzelméhez. Erre egy jó megoldásnak tűnt az RFE, ami ezeket a gyenge változókat kezeli, ami sajnos az adatunk természetéből adódik. 

train[, win:= as.character(win)][win == 1, win:= "Win"]
train[, win:= as.character(win)][win == 0, win:= "Lose"]

test[, win:= as.character(win)][win == 1, win:= "Win"]
test[, win:= as.character(win)][win == 0, win:= "Lose"]

set.seed(2020)
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)
results <- rfe(train[,-c(1)], as.factor(train$win), sizes=c(1:15), rfeControl = control)


pred_prob <- predict(results, newdata = test[,-c(1)])

result_table <- table(pred_prob$pred, test$win)
print(precision(result_table))
print(result_table)

# A precision számunk elég pocsék, ezért nem valószínű, hogy ezt a modellt lesz érdemes majd használni. Ennek oka lehet, hogy az RFE kidobálna nem fontos változókat, azonban nincs semelyik változó sem feltétlen elengedhetetlen magában, ebből arra következtetünk, hogy kevesebb a fontos változó mint az eredetileg gondoltuk.
```

# PCR Modell
```{r}
# Győzelmeket egy külön vektorba tesszük.
winvec <- as.numeric(data$win)

# Dependent változók mátrix formában kellenek a későbbi functionhöz.
depen <- data[, c("win"):= NULL]
depen_names <- names(depen)

depen <- as.matrix(depen, rownames = FALSE)

# KÖNYÖK
ks <- 1:10
tot_within_ss <- sapply(ks, function(k) {
  km_output <- kmeans(depen, k, nstart = 20)
  km_output$tot.withinss
})
tot_within_ss

plot(
  x = ks,
  y = tot_within_ss,
  type = "b"
)
# A konyok alapjan 4 clustert PC-et hasznalunk.

# Ez a function a "Compositional" packageben van benne, azonban nem a sima glm fuggvenyt hasznalja 
# ezert nem tudtam rendesen hasznalni azonban atirva a source code-ot mar jo eredmenyt kapunk
# https://github.com/cran/Compositional/blob/master/R/glm.pcr.R

################################
#### Principal components regression  for binary and poisson regression
################################

glm.pcr <- function(y, x, k = 1) {
  ## y is a binary variable 0, 1
  ## x contains the independent variables
  ## k shows the number of components to keep
  p <- dim(x)[2]
  eig <- prcomp(x, center = FALSE)
  
  values <- eig$sdev^2  ## eigenvalues
  per <- cumsum( values / sum(values) )  ## cumulative proportion of eigenvalues
  vec <- eig$rotation[, 1:k, drop = FALSE]  ## eigenvectors, or principal components
  z <- x %*% vec  ## PCA scores
  
    z <- as.data.frame(z)
    names(z) <- c("zPC1", "zPC2", "zPC3", "zPC4")
    mod <- glm(as.factor(y) ~ ., data = z, family = binomial)
    be <- mod$info[, 1]
  
  list(model = mod, per = per[k], test = t, pca = eig)
}

# Training and validation data, ugyanazzal a sample számmal mint az előzökben
depen.train <- depen[samp,]
winvec.train <- winvec[samp]

depen.valid <- depen[-samp,]
winvec.valid <- winvec[-samp]

model_pcr <- glm.pcr(winvec.train, depen.train, k = 4)
glm_model <- model_pcr$model

test <- tbl_df(predict(model_pcr$pca, newdata = depen.valid))
test <- test[, 1:4]

names(test) <- c("zPC1", "zPC2", "zPC3", "zPC4")
pred_prob <- predict(glm_model, newdata = test, type = "response")


truepos <- c()
falsepos <- c()

ks <- seq(from = min(pred_prob), to = max(pred_prob), by = 0.02)
for (k in ks) {
  pred_response <- rep(0, length(pred_prob))
  pred_response[pred_prob > k] <- 1
  result_table <- table(pred_response, winvec.valid)
  
  
  # Illetve érdekel minket az is, hogy az órán tanult truepositive - falsepositive ábra hogyan néz ki az esetünkben.
  truepos <- append(truepos, (result_table[2,2])/(result_table[2,2]+result_table[1,2]))
  falsepos <- append(falsepos, (result_table[2,1])/(result_table[2,2]+result_table[1,1]))
  
  # Eredmények:
  print(paste("Kritikus érték", k))
  print(precision(result_table))
  print((result_table[2,1])/(result_table[2,2]+result_table[1,1]))
}

plot(falsepos, truepos)
# A szinte egyenes vonalbol arra kovetkeztetek, hogy annyira pontosan tudunk igy elorejelezni mintha szinte random mintank lenne

# Mivel a precision alapján tervezünk választani, ezért a .5-es értéknél választjuk el a győzelmet
pred_response <- rep(0, length(pred_prob))
pred_response[pred_prob > .5] <- 1
table(pred_response, winvec.valid)
```

# Tanulság

## Igazunk lett a PCR modellel, precision szempontjából ez teljesített a legjobban, és az esetek ~57%-ban jó döntést hozhatunk a fogadásunkkal.

Válószínüleg azért nem teljesítettek olyan jól a feature selection modellek, mert a változók önmagukban nem voltak olyan erősek egyenként, azonban egy keverékük már az tudott lenni.

Összességében precision számok:

GLM: 0.5294118

LVQ: 0.5398773

RFE: 0.5284553

PCR: 0.5673077